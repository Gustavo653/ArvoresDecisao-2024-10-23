Analisamos aqui o Iris Dataset com k-NN, Decision Tree usando gini e entropy

Resultados:
O algoritmo Decision Tree com o critério gini e profundidade máxima de 5 (exemplo) apresentou a melhor acurácia, com uma performance superior nos dados de teste.
O critério entropy também gerou bons resultados, mas de forma geral, foi levemente inferior em termos de acurácia.
O k-NN teve resultados competitivos, mas sua acurácia foi um pouco menor em comparação com as Árvores de Decisão, principalmente com valores de k mais altos (exemplo: k=10).
